{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd34ebd-7d75-4dc5-875a-8bc85d071fe4",
   "metadata": {},
   "source": [
    "# Choose Your Own Adventure: Direct S3 Access\n",
    "\n",
    "### Use this notebook to practice skills and techniques you learned in in [`UWG-F2F_S3_Bucket_Access.ipynb`](https://github.com/nasa/gesdisc-cloud-tutorials/blob/main/GES_DISC_Cloud_Notebooks/Cloud_Workshop/UWG/UWG-F2F_S3_Bucket_Access.ipynb). \n",
    "\n",
    "\n",
    "### We provide the necessary code in the first few blocks. Make sure to run these first before experimenting with data search and access. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acec8dc-c8bf-47af-b897-2833380f8b66",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "We included some essentials here, but add to the list if you need additional Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aed28ef-ca94-4cf2-8f00-58ca6c4a65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xarray as xr\n",
    "import s3fs\n",
    "import os\n",
    "from netrc import netrc\n",
    "\n",
    "# Need more Python libraries? Add them below!\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab88b6-964e-4939-adc3-155758253823",
   "metadata": {},
   "source": [
    "### Generate *OR* check for a `.netrc` file\n",
    "\n",
    "If you successfully ran [`UWG-F2F_S3_Bucket_Access.ipynb`](https://github.com/nasa/gesdisc-cloud-tutorials/blob/main/GES_DISC_Cloud_Notebooks/Cloud_Workshop/UWG/UWG-F2F_S3_Bucket_Access.ipynb), this code will run with no errors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4c88aa-6438-46bb-94ba-a20cdf820e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "urs = 'urs.earthdata.nasa.gov'    # Earthdata URL endpoint for authentication\n",
    "prompts = ['Enter NASA Earthdata Login Username: ',\n",
    "           'Enter NASA Earthdata Login Password: ']\n",
    "\n",
    "netrc_name = \".netrc\"\n",
    "\n",
    "# Determine if netrc file exists, and if so, if it includes NASA Earthdata Login Credentials\n",
    "try:\n",
    "    netrcDir = os.path.expanduser(f\"~/{netrc_name}\")\n",
    "    netrc(netrcDir).authenticators(urs)[0]\n",
    "\n",
    "# Below, create a netrc file and prompt user for NASA Earthdata Login Username and Password\n",
    "except FileNotFoundError:\n",
    "    homeDir = os.path.expanduser(\"~\")\n",
    "    Popen('touch {0}{2} | echo machine {1} >> {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n",
    "    Popen('echo login {} >> {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    Popen('echo \\'password {} \\'>> {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    # Set restrictive permissions\n",
    "    Popen('chmod 0600 {0}{1}'.format(homeDir + os.sep, netrc_name), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19215731-ce52-4968-adca-446283b0f3b8",
   "metadata": {},
   "source": [
    "### **YOUR TURN!** \n",
    "\n",
    "### Which data collection(s) do you want to work with? How would you like to obtain S3 URLs?\n",
    "\n",
    "Choose your method of obtaining S3 URLs for your data collection of interest. \n",
    "\n",
    "1. Using the \"Download Data\" option in [Earthdata Search](https://search.earthdata.nasa.gov/search?ff=Available%20from%20AWS%20Cloud&fdc=Goddard%2BEarth%2BSciences%2BData%2Band%2BInformation%2BServices%2BCenter%2B%2528GES%2BDISC%252) and selecting files from the \"AWS S3 Access\" tab\n",
    "2. Using the CMR API to perform a collection and/or granule search\n",
    "3. Using the GES DISC \"Subset/Get Data\" dialog box *(feature coming soon)*\n",
    "4. Using knowledge of the structure of granule IDs and the S3 Bucket/Object Prefix of a particular collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "944bd1fb-53e8-487f-9b81-774780b3e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out here!\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hint: If you want to make a list in Python, add your items inside square brackets, separate them with commas and name your list!\n",
    "# i.e. groceries = ['bread', 'cheese', 'milk']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe8088-9d1f-410a-a480-e619a78a4e8d",
   "metadata": {},
   "source": [
    "### Got your single granule S3 URL or list of S3 URLs?\n",
    "\n",
    "### Choose an appropriate DAAC S3 credential endpoint and start up your S3 File System session!\n",
    "\n",
    "You can find a list of DAAC S3 credential endpoints here:\n",
    "- GES DISC: https://data.gesdisc.earthdata.nasa.gov/s3credentials\n",
    "- GHRC: https://data.ghrc.earthdata.nasa.gov/s3credentials\n",
    "- LP DAAC: https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials\n",
    "- NSIDC: https://data.nsidc.earthdatacloud.nasa.gov/s3credentials\n",
    "- ORNL DAAC: https://data.ornldaac.earthdata.nasa.gov/s3credentials\n",
    "- PO.DAAC: https://archive.podaac.earthdata.nasa.gov/s3credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eda3e91-f0fd-4004-92b1-01e01ae99778",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auth_link' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Which DAAC S3 credential endpoint to use? Choose from the list and paste the URL below\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# auth_link = '__paste URL here ___'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Define a function that starts an S3 File System session\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbegin_s3_direct_access\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mauth_link\u001b[49m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(auth_link)\n\u001b[1;32m      7\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'auth_link' is not defined"
     ]
    }
   ],
   "source": [
    "# Which DAAC S3 credential endpoint to use? Choose from the list and paste the URL below\n",
    "# auth_link = \"__paste URL here ___\"\n",
    "\n",
    "# Define a function that starts an S3 File System session\n",
    "def begin_s3_direct_access(url: str=auth_link):\n",
    "    print(auth_link)\n",
    "    response = requests.get(url).json()\n",
    "    return s3fs.S3FileSystem(key=response['accessKeyId'],\n",
    "                             secret=response['secretAccessKey'],\n",
    "                             token=response['sessionToken'])\n",
    "\n",
    "# Use the function and specify the auth_link to open the S3 File System\n",
    "fs = begin_s3_direct_access(auth_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f99a10-034c-45bb-8ae5-b5cc27c49284",
   "metadata": {},
   "source": [
    "### Open up one, or multiple, granules using Python's xarray\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4526672-44f1-4fec-a00d-77d35ce3731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if you can open a single granule using xarray's open_dataset() function\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f893628-bcfb-4e63-aa6b-89f78ab48a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now see if you can write a way to open *multiple* granules using xarray's open_mfdataset() function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hint: Each granule still needs to be opened with the S3 File System before operation by the xarray open_mfdataset function. However, this input can still be a list.\n",
    "# Here is how you can iterate a function and write the output to a list\n",
    "# outputs_list = [function() for item in input_list]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
